{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd4a83fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12847, 277, 15068, 4501, 3, 12297, 3399, 16, 5964, 7115, 9, 55, 531, 25, 241, 12, 129, 394, 44, 492, 3326, 15068, 58, 148, 56, 43, 8, 1004, 6, 474, 48, 30, 39, 4793, 230, 5, 2721, 6, 1600, 1630, 727, 1715, 1150, 4501, 15068, 16127, 6, 9137, 2659, 5595, 45, 301, 782, 3624, 14627, 15, 12612, 277, 5, 216, 56, 36, 2119, 3, 9, 19529, 593, 853, 21, 921, 113, 2746, 12, 129, 394, 28, 70, 17712, 1098, 5, 216, 56, 3884, 25, 762, 25, 174, 12, 214, 12, 5978, 16, 3, 9, 3, 23405, 4547, 15068, 2259, 6, 379, 2097, 6, 5459, 6, 13618, 7, 6, 3604, 1801, 11, 27856, 6, 303, 24190, 11, 1472, 251, 5, 37, 583, 12, 36, 16, 8, 853, 19, 25264, 399, 568, 6, 11, 21, 21380, 7, 34, 19, 339, 5, 15746, 26, 16, 8, 583, 56, 36, 893, 3, 9, 3, 17, 18, 9486, 42, 3, 9, 1409, 29, 11, 25, 56, 36, 12246, 5977, 13, 284, 3604, 24, 19, 2657, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 1. Load the T5 tokenizer.\n",
    "# It's recommended to use a tokenizer from a pre-trained model like 't5-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "# 2. Load the C4 dataset.\n",
    "# The `streaming=True` argument is useful for huge datasets like C4 to avoid downloading the whole thing.\n",
    "c4_dataset = load_dataset(\"allenai/c4\", \"en\", split=\"train\", streaming=True)\n",
    "\n",
    "# 3. Define a tokenization function.\n",
    "# This function will be applied to each batch of data.\n",
    "def tokenize_function(examples):\n",
    "    # The T5 model expects a prefix for the task, for example \"denoise text: \".\n",
    "    # This is important for T5's pre-training objective.\n",
    "    # However, for a simple tokenization, we can just process the \"text\" field.\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "# 4. Apply the tokenizer to the dataset using the map function.\n",
    "# `batched=True` processes the data in batches, which is much faster.\n",
    "tokenized_c4 = c4_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# You can now iterate through the tokenized dataset.\n",
    "for example in tokenized_c4:\n",
    "    print(example[\"input_ids\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73d17fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Vocabulary size: 37\n",
      "Starting training...\n",
      "Epoch [1/20], Step [1/7], Loss: 3.7109\n",
      "Epoch [1/20], Step [2/7], Loss: 3.6706\n",
      "Epoch [1/20], Step [3/7], Loss: 3.6618\n",
      "Epoch [1/20], Step [4/7], Loss: 3.6554\n",
      "Epoch [1/20], Step [5/7], Loss: 3.6641\n",
      "Epoch [1/20], Step [6/7], Loss: 3.6367\n",
      "Epoch [1/20], Step [7/7], Loss: 3.6520\n",
      "Epoch [2/20], Step [1/7], Loss: 3.2856\n",
      "Epoch [2/20], Step [2/7], Loss: 3.2701\n",
      "Epoch [2/20], Step [3/7], Loss: 3.2480\n",
      "Epoch [2/20], Step [4/7], Loss: 3.3315\n",
      "Epoch [2/20], Step [5/7], Loss: 3.2014\n",
      "Epoch [2/20], Step [6/7], Loss: 3.2693\n",
      "Epoch [2/20], Step [7/7], Loss: 3.2356\n",
      "Epoch [3/20], Step [1/7], Loss: 3.5368\n",
      "Epoch [3/20], Step [2/7], Loss: 2.8795\n",
      "Epoch [3/20], Step [3/7], Loss: 2.9374\n",
      "Epoch [3/20], Step [4/7], Loss: 2.7491\n",
      "Epoch [3/20], Step [5/7], Loss: 2.8209\n",
      "Epoch [3/20], Step [6/7], Loss: 2.7460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130231/3157935005.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  l_out_pool2 = torch.floor(torch.tensor((l_out_conv2 - 2) / 2)) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Step [7/7], Loss: 2.7118\n",
      "Epoch [4/20], Step [1/7], Loss: 2.7884\n",
      "Epoch [4/20], Step [2/7], Loss: 2.9727\n",
      "Epoch [4/20], Step [3/7], Loss: 2.7151\n",
      "Epoch [4/20], Step [4/7], Loss: 2.7521\n",
      "Epoch [4/20], Step [5/7], Loss: 2.9391\n",
      "Epoch [4/20], Step [6/7], Loss: 2.8336\n",
      "Epoch [4/20], Step [7/7], Loss: 2.9083\n",
      "Epoch [5/20], Step [1/7], Loss: 2.7260\n",
      "Epoch [5/20], Step [2/7], Loss: 2.7982\n",
      "Epoch [5/20], Step [3/7], Loss: 2.9113\n",
      "Epoch [5/20], Step [4/7], Loss: 2.3345\n",
      "Epoch [5/20], Step [5/7], Loss: 2.1588\n",
      "Epoch [5/20], Step [6/7], Loss: 2.1593\n",
      "Epoch [5/20], Step [7/7], Loss: 2.2315\n",
      "Epoch [6/20], Step [1/7], Loss: 1.4436\n",
      "Epoch [6/20], Step [2/7], Loss: 1.2955\n",
      "Epoch [6/20], Step [3/7], Loss: 1.6238\n",
      "Epoch [6/20], Step [4/7], Loss: 2.1200\n",
      "Epoch [6/20], Step [5/7], Loss: 1.8380\n",
      "Epoch [6/20], Step [6/7], Loss: 1.7514\n",
      "Epoch [6/20], Step [7/7], Loss: 1.6431\n",
      "Epoch [7/20], Step [1/7], Loss: 1.3238\n",
      "Epoch [7/20], Step [2/7], Loss: 1.2145\n",
      "Epoch [7/20], Step [3/7], Loss: 1.7978\n",
      "Epoch [7/20], Step [4/7], Loss: 1.6657\n",
      "Epoch [7/20], Step [5/7], Loss: 1.6501\n",
      "Epoch [7/20], Step [6/7], Loss: 1.6469\n",
      "Epoch [7/20], Step [7/7], Loss: 1.4383\n",
      "Epoch [8/20], Step [1/7], Loss: 1.5700\n",
      "Epoch [8/20], Step [2/7], Loss: 1.2023\n",
      "Epoch [8/20], Step [3/7], Loss: 1.3192\n",
      "Epoch [8/20], Step [4/7], Loss: 1.1158\n",
      "Epoch [8/20], Step [5/7], Loss: 1.0496\n",
      "Epoch [8/20], Step [6/7], Loss: 1.0011\n",
      "Epoch [8/20], Step [7/7], Loss: 0.9057\n",
      "Epoch [9/20], Step [1/7], Loss: 1.0839\n",
      "Epoch [9/20], Step [2/7], Loss: 0.6836\n",
      "Epoch [9/20], Step [3/7], Loss: 0.6346\n",
      "Epoch [9/20], Step [4/7], Loss: 0.4844\n",
      "Epoch [9/20], Step [5/7], Loss: 0.7037\n",
      "Epoch [9/20], Step [6/7], Loss: 0.8145\n",
      "Epoch [9/20], Step [7/7], Loss: 0.7023\n",
      "Epoch [10/20], Step [1/7], Loss: 0.0735\n",
      "Epoch [10/20], Step [2/7], Loss: 0.0437\n",
      "Epoch [10/20], Step [3/7], Loss: 0.1617\n",
      "Epoch [10/20], Step [4/7], Loss: 0.2437\n",
      "Epoch [10/20], Step [5/7], Loss: 0.3822\n",
      "Epoch [10/20], Step [6/7], Loss: 0.4081\n",
      "Epoch [10/20], Step [7/7], Loss: 0.5241\n",
      "Epoch [11/20], Step [1/7], Loss: 0.0741\n",
      "Epoch [11/20], Step [2/7], Loss: 0.3561\n",
      "Epoch [11/20], Step [3/7], Loss: 0.2576\n",
      "Epoch [11/20], Step [4/7], Loss: 0.2721\n",
      "Epoch [11/20], Step [5/7], Loss: 0.2875\n",
      "Epoch [11/20], Step [6/7], Loss: 0.2955\n",
      "Epoch [11/20], Step [7/7], Loss: 0.2535\n",
      "Epoch [12/20], Step [1/7], Loss: 0.0298\n",
      "Epoch [12/20], Step [2/7], Loss: 0.1796\n",
      "Epoch [12/20], Step [3/7], Loss: 0.4457\n",
      "Epoch [12/20], Step [4/7], Loss: 0.7244\n",
      "Epoch [12/20], Step [5/7], Loss: 0.5890\n",
      "Epoch [12/20], Step [6/7], Loss: 0.6573\n",
      "Epoch [12/20], Step [7/7], Loss: 0.5650\n",
      "Epoch [13/20], Step [1/7], Loss: 0.0017\n",
      "Epoch [13/20], Step [2/7], Loss: 0.1937\n",
      "Epoch [13/20], Step [3/7], Loss: 0.1298\n",
      "Epoch [13/20], Step [4/7], Loss: 0.4717\n",
      "Epoch [13/20], Step [5/7], Loss: 0.3878\n",
      "Epoch [13/20], Step [6/7], Loss: 0.3279\n",
      "Epoch [13/20], Step [7/7], Loss: 0.2928\n",
      "Epoch [14/20], Step [1/7], Loss: 1.1123\n",
      "Epoch [14/20], Step [2/7], Loss: 0.5727\n",
      "Epoch [14/20], Step [3/7], Loss: 0.3840\n",
      "Epoch [14/20], Step [4/7], Loss: 0.2972\n",
      "Epoch [14/20], Step [5/7], Loss: 0.2789\n",
      "Epoch [14/20], Step [6/7], Loss: 0.2336\n",
      "Epoch [14/20], Step [7/7], Loss: 0.2017\n",
      "Epoch [15/20], Step [1/7], Loss: 0.0346\n",
      "Epoch [15/20], Step [2/7], Loss: 0.0347\n",
      "Epoch [15/20], Step [3/7], Loss: 0.0349\n",
      "Epoch [15/20], Step [4/7], Loss: 0.0299\n",
      "Epoch [15/20], Step [5/7], Loss: 0.0250\n",
      "Epoch [15/20], Step [6/7], Loss: 0.0220\n",
      "Epoch [15/20], Step [7/7], Loss: 0.0306\n",
      "Epoch [16/20], Step [1/7], Loss: 0.5794\n",
      "Epoch [16/20], Step [2/7], Loss: 0.3182\n",
      "Epoch [16/20], Step [3/7], Loss: 0.2339\n",
      "Epoch [16/20], Step [4/7], Loss: 0.1766\n",
      "Epoch [16/20], Step [5/7], Loss: 0.1703\n",
      "Epoch [16/20], Step [6/7], Loss: 0.1519\n",
      "Epoch [16/20], Step [7/7], Loss: 0.1306\n",
      "Epoch [17/20], Step [1/7], Loss: 0.0012\n",
      "Epoch [17/20], Step [2/7], Loss: 0.0360\n",
      "Epoch [17/20], Step [3/7], Loss: 0.1609\n",
      "Epoch [17/20], Step [4/7], Loss: 0.1262\n",
      "Epoch [17/20], Step [5/7], Loss: 0.1017\n",
      "Epoch [17/20], Step [6/7], Loss: 0.1043\n",
      "Epoch [17/20], Step [7/7], Loss: 0.1367\n",
      "Epoch [18/20], Step [1/7], Loss: 0.0038\n",
      "Epoch [18/20], Step [2/7], Loss: 0.0753\n",
      "Epoch [18/20], Step [3/7], Loss: 0.0502\n",
      "Epoch [18/20], Step [4/7], Loss: 0.0387\n",
      "Epoch [18/20], Step [5/7], Loss: 0.5492\n",
      "Epoch [18/20], Step [6/7], Loss: 0.4722\n",
      "Epoch [18/20], Step [7/7], Loss: 0.4047\n",
      "Epoch [19/20], Step [1/7], Loss: 0.0002\n",
      "Epoch [19/20], Step [2/7], Loss: 0.0002\n",
      "Epoch [19/20], Step [3/7], Loss: 0.0027\n",
      "Epoch [19/20], Step [4/7], Loss: 0.0021\n",
      "Epoch [19/20], Step [5/7], Loss: 0.0018\n",
      "Epoch [19/20], Step [6/7], Loss: 0.0018\n",
      "Epoch [19/20], Step [7/7], Loss: 0.0028\n",
      "Epoch [20/20], Step [1/7], Loss: 0.0150\n",
      "Epoch [20/20], Step [2/7], Loss: 0.0189\n",
      "Epoch [20/20], Step [3/7], Loss: 0.0212\n",
      "Epoch [20/20], Step [4/7], Loss: 0.1302\n",
      "Epoch [20/20], Step [5/7], Loss: 0.1549\n",
      "Epoch [20/20], Step [6/7], Loss: 0.1490\n",
      "Epoch [20/20], Step [7/7], Loss: 0.2719\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 1. Define a simple text dataset and vocabulary ---\n",
    "# FIX: Added much longer sentences to the training data.\n",
    "TEXT_DATA = [\n",
    "    \"hello world and this is a much longer sentence than before\",\n",
    "    \"python programming is fun and easy to learn especially for beginners\",\n",
    "    \"i love deep learning with convolutional neural networks and attention\",\n",
    "    \"deep learning is a powerful tool in artificial intelligence for language modeling tasks\"\n",
    "]\n",
    "\n",
    "# Create vocabulary\n",
    "vocab = sorted(list(set(\" \".join(TEXT_DATA).split())))\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_data, word_to_idx, sequence_length):\n",
    "        self.sequences = []\n",
    "        for sentence in text_data:\n",
    "            words = sentence.split()\n",
    "            # This condition will now be met for the longer sentences\n",
    "            if len(words) > sequence_length:\n",
    "                for i in range(len(words) - sequence_length):\n",
    "                    input_seq = [word_to_idx[word] for word in words[i:i+sequence_length]]\n",
    "                    target_word = word_to_idx[words[i+sequence_length]]\n",
    "                    self.sequences.append((torch.tensor(input_seq), torch.tensor(target_word)))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx]\n",
    "\n",
    "# --- 2. Attention Mechanism for 1D sequences ---\n",
    "class AttentionMessagePassing(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(AttentionMessagePassing, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.query_proj = nn.Linear(in_features, in_features // 2)\n",
    "        self.key_proj = nn.Linear(in_features, in_features // 2)\n",
    "        self.value_proj = nn.Linear(in_features, in_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, in_features = x.shape\n",
    "        query = self.query_proj(x)\n",
    "        key = self.key_proj(x)\n",
    "        value = self.value_proj(x)\n",
    "        key_t = key.permute(0, 2, 1)\n",
    "        \n",
    "        attention_scores = torch.bmm(query, key_t)\n",
    "        attention_scores = attention_scores / np.sqrt(query.size(-1))\n",
    "        \n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(device)\n",
    "        attention_scores.masked_fill_(mask, -1e9)\n",
    "        \n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "        message_passed_features = torch.bmm(attention_weights, value)\n",
    "        \n",
    "        output = message_passed_features + x\n",
    "        return output\n",
    "\n",
    "# --- 3. The new TextCNN Architecture with Attention ---\n",
    "class AttentionTextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, sequence_length):\n",
    "        super(AttentionTextCNN, self).__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=embedding_dim, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.final_seq_len = self._compute_final_seq_len()\n",
    "        \n",
    "        self.attention_block = AttentionMessagePassing(in_features=256)\n",
    "        \n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * self.final_seq_len, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, vocab_size)\n",
    "        )\n",
    "\n",
    "    def _compute_final_seq_len(self):\n",
    "        l_in = self.sequence_length\n",
    "        l_out_conv1 = (l_in + 2*1 - 3) + 1\n",
    "        l_out_pool1 = torch.floor(torch.tensor((l_out_conv1 - 2) / 2)) + 1\n",
    "        l_out_conv2 = (l_out_pool1 + 2*1 - 3) + 1\n",
    "        l_out_pool2 = torch.floor(torch.tensor((l_out_conv2 - 2) / 2)) + 1\n",
    "        \n",
    "        return int(l_out_pool2.item())\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.embedding(x).permute(0, 2, 1)\n",
    "        conv_features = self.conv_block(embeddings)\n",
    "        conv_features_t = conv_features.permute(0, 2, 1)\n",
    "        attended_features = self.attention_block(conv_features_t)\n",
    "        logits = self.fc_block(attended_features)\n",
    "        return logits\n",
    "\n",
    "def train_model():\n",
    "    # Hyperparameters\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 2\n",
    "    num_epochs = 20\n",
    "    # FIX: Increased sequence length to a value that won't result in an empty tensor.\n",
    "    sequence_length = 8\n",
    "    embedding_dim = 128\n",
    "    \n",
    "    # Data loading\n",
    "    train_dataset = TextDataset(TEXT_DATA, word_to_idx, sequence_length)\n",
    "    \n",
    "    # FIX: Added a check to prevent the error\n",
    "    if len(train_dataset) == 0:\n",
    "        print(\"Error: Dataset is empty.\")\n",
    "        print(f\"Please increase the length of sentences in TEXT_DATA or decrease the `sequence_length` (currently {sequence_length}).\")\n",
    "        return\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = AttentionTextCNN(vocab_size, embedding_dim, sequence_length).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if (i+1) % 1 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/(i+1):.4f}')\n",
    "    \n",
    "    print(\"Training finished.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e318639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading a small streaming portion of the C4 dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_142525/4073020323.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  l_out_pool2 = torch.floor(torch.tensor((l_out_conv2 - 2) / 2)) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch [1/25], Step [50], Loss: 8.0989\n",
      "Epoch [1/25], Total Loss: 554.4425\n",
      "Epoch [2/25], Step [50], Loss: 7.6237\n",
      "Epoch [2/25], Total Loss: 475.0718\n",
      "Epoch [3/25], Step [50], Loss: 7.3587\n",
      "Epoch [3/25], Total Loss: 462.4314\n",
      "Epoch [4/25], Step [50], Loss: 7.2382\n",
      "Epoch [4/25], Total Loss: 453.6940\n",
      "Epoch [5/25], Step [50], Loss: 7.0704\n",
      "Epoch [5/25], Total Loss: 448.0959\n",
      "Epoch [6/25], Step [50], Loss: 7.0998\n",
      "Epoch [6/25], Total Loss: 440.3498\n",
      "Epoch [7/25], Step [50], Loss: 6.9436\n",
      "Epoch [7/25], Total Loss: 438.2087\n",
      "Epoch [8/25], Step [50], Loss: 6.8748\n",
      "Epoch [8/25], Total Loss: 430.5942\n",
      "Epoch [9/25], Step [50], Loss: 6.7596\n",
      "Epoch [9/25], Total Loss: 422.2487\n",
      "Epoch [10/25], Step [50], Loss: 6.7566\n",
      "Epoch [10/25], Total Loss: 420.0503\n",
      "Epoch [11/25], Step [50], Loss: 6.5045\n",
      "Epoch [11/25], Total Loss: 411.4892\n",
      "Epoch [12/25], Step [50], Loss: 6.4505\n",
      "Epoch [12/25], Total Loss: 402.6581\n",
      "Epoch [13/25], Step [50], Loss: 6.3982\n",
      "Epoch [13/25], Total Loss: 396.5994\n",
      "Epoch [14/25], Step [50], Loss: 6.4046\n",
      "Epoch [14/25], Total Loss: 393.1120\n",
      "Epoch [15/25], Step [50], Loss: 6.2611\n",
      "Epoch [15/25], Total Loss: 387.8590\n",
      "Epoch [16/25], Step [50], Loss: 6.2179\n",
      "Epoch [16/25], Total Loss: 386.0258\n",
      "Epoch [17/25], Step [50], Loss: 6.2293\n",
      "Epoch [17/25], Total Loss: 387.3775\n",
      "Epoch [18/25], Step [50], Loss: 6.3739\n",
      "Epoch [18/25], Total Loss: 382.0998\n",
      "Epoch [19/25], Step [50], Loss: 6.3097\n",
      "Epoch [19/25], Total Loss: 384.8144\n",
      "Epoch [20/25], Step [50], Loss: 6.2718\n",
      "Epoch [20/25], Total Loss: 380.5632\n",
      "Epoch [21/25], Step [50], Loss: 6.1913\n",
      "Epoch [21/25], Total Loss: 391.6938\n",
      "Epoch [22/25], Step [50], Loss: 6.1422\n",
      "Epoch [22/25], Total Loss: 386.2757\n",
      "Epoch [23/25], Step [50], Loss: 6.2188\n",
      "Epoch [23/25], Total Loss: 385.5671\n",
      "Epoch [24/25], Step [50], Loss: 6.1240\n",
      "Epoch [24/25], Total Loss: 386.0963\n",
      "Epoch [25/25], Step [50], Loss: 6.1949\n",
      "Epoch [25/25], Total Loss: 384.7790\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 1. Attention Mechanism for 1D sequences ---\n",
    "class AttentionMessagePassing(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(AttentionMessagePassing, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.query_proj = nn.Linear(in_features, in_features // 2)\n",
    "        self.key_proj = nn.Linear(in_features, in_features // 2)\n",
    "        self.value_proj = nn.Linear(in_features, in_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, in_features = x.shape\n",
    "        query = self.query_proj(x)\n",
    "        key = self.key_proj(x)\n",
    "        value = self.value_proj(x)\n",
    "        key_t = key.permute(0, 2, 1)\n",
    "        \n",
    "        attention_scores = torch.bmm(query, key_t)\n",
    "        attention_scores = attention_scores / np.sqrt(query.size(-1))\n",
    "        \n",
    "        # We need a causality mask for language modeling\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(device)\n",
    "        attention_scores.masked_fill_(mask, -1e9)\n",
    "        \n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "        message_passed_features = torch.bmm(attention_weights, value)\n",
    "        \n",
    "        output = message_passed_features + x\n",
    "        return output\n",
    "\n",
    "# --- 2. The new TextCNN Architecture with Attention ---\n",
    "class AttentionTextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, sequence_length):\n",
    "        super(AttentionTextCNN, self).__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            # Conv1d expects input shape (batch, channels, sequence_length)\n",
    "            nn.Conv1d(in_channels=embedding_dim, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.final_seq_len = self._compute_final_seq_len()\n",
    "        \n",
    "        self.attention_block = AttentionMessagePassing(in_features=256)\n",
    "        \n",
    "        # FIX: Removed nn.Flatten() and adjusted Linear layer to work on a per-token basis.\n",
    "        # This is the correct way to build a sequence-to-sequence model for language modeling.\n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, vocab_size)\n",
    "        )\n",
    "\n",
    "    def _compute_final_seq_len(self):\n",
    "        l_in = self.sequence_length\n",
    "        l_out_conv1 = (l_in + 2*1 - 3) + 1\n",
    "        l_out_pool1 = torch.floor(torch.tensor((l_out_conv1 - 2) / 2)) + 1\n",
    "        l_out_conv2 = (l_out_pool1 + 2*1 - 3) + 1\n",
    "        l_out_pool2 = torch.floor(torch.tensor((l_out_conv2 - 2) / 2)) + 1\n",
    "        \n",
    "        return int(l_out_pool2.item())\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.embedding(x).permute(0, 2, 1)\n",
    "        conv_features = self.conv_block(embeddings)\n",
    "        conv_features_t = conv_features.permute(0, 2, 1)\n",
    "        attended_features = self.attention_block(conv_features_t)\n",
    "        # FIX: The fc_block now processes the attended features without flattening.\n",
    "        logits = self.fc_block(attended_features)\n",
    "        return logits\n",
    "\n",
    "# --- 3. Main training function updated for C4 dataset ---\n",
    "def train_model():\n",
    "    # Hyperparameters\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 8\n",
    "    num_epochs = 25\n",
    "    sequence_length = 128\n",
    "    embedding_dim = 128\n",
    "    \n",
    "    # ----------------------------------------\n",
    "    # 1. Load C4 dataset (streaming) and Bert tokenizer\n",
    "    # ----------------------------------------\n",
    "    print(\"Loading a small streaming portion of the C4 dataset...\")\n",
    "    dataset = load_dataset(\"allenai/c4\", \"en\", split=\"train\", streaming=True)\n",
    "    \n",
    "    # Use a simpler, pre-trained tokenizer: BertTokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    vocab_size = len(tokenizer)\n",
    "    \n",
    "    # We will use a smaller sample for a quicker demonstration.\n",
    "    dataset_sample = dataset.take(500)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 2. Pre-process the dataset with the tokenizer\n",
    "    # ----------------------------------------\n",
    "    def preprocess_function(examples):\n",
    "        inputs = examples[\"text\"]\n",
    "        tokenized_input = tokenizer(\n",
    "            inputs,\n",
    "            max_length=sequence_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Shift the labels for next-token prediction\n",
    "        input_ids = tokenized_input['input_ids'].squeeze(0)\n",
    "        labels = torch.cat((input_ids[1:], torch.tensor([tokenizer.pad_token_id])))\n",
    "        \n",
    "        return {\"input_ids\": input_ids, \"labels\": labels}\n",
    "    \n",
    "    # Apply the preprocessing to the streaming dataset\n",
    "    processed_dataset = dataset_sample.map(preprocess_function, batched=False)\n",
    "    \n",
    "    # We use the processed streaming dataset directly with the DataLoader\n",
    "    train_loader = DataLoader(processed_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # ----------------------------------------\n",
    "    # 3. Model, Loss, and Optimizer\n",
    "    # ----------------------------------------\n",
    "    model = AttentionTextCNN(vocab_size, embedding_dim, sequence_length).to(device)\n",
    "    # Ignore the pad token in the loss\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    # ----------------------------------------\n",
    "    # 4. Training Loop\n",
    "    # ----------------------------------------\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        # FIX: The total number of batches is unknown, so we can't use len(train_loader).\n",
    "        # We will track the step count manually.\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            # Batches from DataLoader are already tensors\n",
    "            inputs = batch[\"input_ids\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # The model's output sequence length might be different from the input\n",
    "            # due to pooling. We need to truncate the labels to match.\n",
    "            outputs_seq_len = outputs.size(1)\n",
    "            labels = labels[:, :outputs_seq_len]\n",
    "\n",
    "            # Reshape for loss calculation: (B*L, V) vs (B*L)\n",
    "            outputs_flat = outputs.view(-1, outputs.size(-1))\n",
    "            # FIX: Use .reshape() instead of .view() to handle non-contiguous tensors\n",
    "            labels_flat = labels.reshape(-1)\n",
    "            \n",
    "            loss = criterion(outputs_flat, labels_flat)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # FIX: The total number of batches is unknown, so average loss is not meaningful.\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Total Loss: {total_loss:.4f}')\n",
    "    \n",
    "    print(\"Training finished.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
