{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd4a83fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mputo/.local/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12847, 277, 15068, 4501, 3, 12297, 3399, 16, 5964, 7115, 9, 55, 531, 25, 241, 12, 129, 394, 44, 492, 3326, 15068, 58, 148, 56, 43, 8, 1004, 6, 474, 48, 30, 39, 4793, 230, 5, 2721, 6, 1600, 1630, 727, 1715, 1150, 4501, 15068, 16127, 6, 9137, 2659, 5595, 45, 301, 782, 3624, 14627, 15, 12612, 277, 5, 216, 56, 36, 2119, 3, 9, 19529, 593, 853, 21, 921, 113, 2746, 12, 129, 394, 28, 70, 17712, 1098, 5, 216, 56, 3884, 25, 762, 25, 174, 12, 214, 12, 5978, 16, 3, 9, 3, 23405, 4547, 15068, 2259, 6, 379, 2097, 6, 5459, 6, 13618, 7, 6, 3604, 1801, 11, 27856, 6, 303, 24190, 11, 1472, 251, 5, 37, 583, 12, 36, 16, 8, 853, 19, 25264, 399, 568, 6, 11, 21, 21380, 7, 34, 19, 339, 5, 15746, 26, 16, 8, 583, 56, 36, 893, 3, 9, 3, 17, 18, 9486, 42, 3, 9, 1409, 29, 11, 25, 56, 36, 12246, 5977, 13, 284, 3604, 24, 19, 2657, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 1. Load the T5 tokenizer.\n",
    "# It's recommended to use a tokenizer from a pre-trained model like 't5-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "# 2. Load the C4 dataset.\n",
    "# The `streaming=True` argument is useful for huge datasets like C4 to avoid downloading the whole thing.\n",
    "c4_dataset = load_dataset(\"allenai/c4\", \"en\", split=\"train\", streaming=True)\n",
    "\n",
    "# 3. Define a tokenization function.\n",
    "# This function will be applied to each batch of data.\n",
    "def tokenize_function(examples):\n",
    "    # The T5 model expects a prefix for the task, for example \"denoise text: \".\n",
    "    # This is important for T5's pre-training objective.\n",
    "    # However, for a simple tokenization, we can just process the \"text\" field.\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "# 4. Apply the tokenizer to the dataset using the map function.\n",
    "# `batched=True` processes the data in batches, which is much faster.\n",
    "tokenized_c4 = c4_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# You can now iterate through the tokenized dataset.\n",
    "for example in tokenized_c4:\n",
    "    print(example[\"input_ids\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73d17fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Vocabulary size: 37\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4158/3157935005.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  l_out_pool2 = torch.floor(torch.tensor((l_out_conv2 - 2) / 2)) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [1/7], Loss: 3.5055\n",
      "Epoch [1/20], Step [2/7], Loss: 3.5048\n",
      "Epoch [1/20], Step [3/7], Loss: 3.5556\n",
      "Epoch [1/20], Step [4/7], Loss: 3.5737\n",
      "Epoch [1/20], Step [5/7], Loss: 3.6062\n",
      "Epoch [1/20], Step [6/7], Loss: 3.6068\n",
      "Epoch [1/20], Step [7/7], Loss: 3.5356\n",
      "Epoch [2/20], Step [1/7], Loss: 3.0164\n",
      "Epoch [2/20], Step [2/7], Loss: 3.3542\n",
      "Epoch [2/20], Step [3/7], Loss: 3.2354\n",
      "Epoch [2/20], Step [4/7], Loss: 3.3654\n",
      "Epoch [2/20], Step [5/7], Loss: 3.4057\n",
      "Epoch [2/20], Step [6/7], Loss: 3.2739\n",
      "Epoch [2/20], Step [7/7], Loss: 3.2412\n",
      "Epoch [3/20], Step [1/7], Loss: 3.0110\n",
      "Epoch [3/20], Step [2/7], Loss: 3.0959\n",
      "Epoch [3/20], Step [3/7], Loss: 2.7066\n",
      "Epoch [3/20], Step [4/7], Loss: 2.7557\n",
      "Epoch [3/20], Step [5/7], Loss: 3.0402\n",
      "Epoch [3/20], Step [6/7], Loss: 2.8373\n",
      "Epoch [3/20], Step [7/7], Loss: 2.7417\n",
      "Epoch [4/20], Step [1/7], Loss: 2.2442\n",
      "Epoch [4/20], Step [2/7], Loss: 2.3088\n",
      "Epoch [4/20], Step [3/7], Loss: 2.1260\n",
      "Epoch [4/20], Step [4/7], Loss: 2.0433\n",
      "Epoch [4/20], Step [5/7], Loss: 2.1352\n",
      "Epoch [4/20], Step [6/7], Loss: 2.0577\n",
      "Epoch [4/20], Step [7/7], Loss: 2.2903\n",
      "Epoch [5/20], Step [1/7], Loss: 2.6069\n",
      "Epoch [5/20], Step [2/7], Loss: 2.1634\n",
      "Epoch [5/20], Step [3/7], Loss: 2.1639\n",
      "Epoch [5/20], Step [4/7], Loss: 2.3418\n",
      "Epoch [5/20], Step [5/7], Loss: 2.2676\n",
      "Epoch [5/20], Step [6/7], Loss: 2.2052\n",
      "Epoch [5/20], Step [7/7], Loss: 2.3103\n",
      "Epoch [6/20], Step [1/7], Loss: 2.5423\n",
      "Epoch [6/20], Step [2/7], Loss: 2.0880\n",
      "Epoch [6/20], Step [3/7], Loss: 1.5514\n",
      "Epoch [6/20], Step [4/7], Loss: 1.3167\n",
      "Epoch [6/20], Step [5/7], Loss: 1.2604\n",
      "Epoch [6/20], Step [6/7], Loss: 1.2412\n",
      "Epoch [6/20], Step [7/7], Loss: 1.3669\n",
      "Epoch [7/20], Step [1/7], Loss: 0.7167\n",
      "Epoch [7/20], Step [2/7], Loss: 0.6875\n",
      "Epoch [7/20], Step [3/7], Loss: 0.7069\n",
      "Epoch [7/20], Step [4/7], Loss: 1.0147\n",
      "Epoch [7/20], Step [5/7], Loss: 1.2258\n",
      "Epoch [7/20], Step [6/7], Loss: 1.2288\n",
      "Epoch [7/20], Step [7/7], Loss: 1.1816\n",
      "Epoch [8/20], Step [1/7], Loss: 0.8942\n",
      "Epoch [8/20], Step [2/7], Loss: 1.0039\n",
      "Epoch [8/20], Step [3/7], Loss: 1.0273\n",
      "Epoch [8/20], Step [4/7], Loss: 0.8541\n",
      "Epoch [8/20], Step [5/7], Loss: 1.0853\n",
      "Epoch [8/20], Step [6/7], Loss: 1.0561\n",
      "Epoch [8/20], Step [7/7], Loss: 0.9722\n",
      "Epoch [9/20], Step [1/7], Loss: 1.2588\n",
      "Epoch [9/20], Step [2/7], Loss: 0.6594\n",
      "Epoch [9/20], Step [3/7], Loss: 0.6251\n",
      "Epoch [9/20], Step [4/7], Loss: 0.6464\n",
      "Epoch [9/20], Step [5/7], Loss: 0.8248\n",
      "Epoch [9/20], Step [6/7], Loss: 0.6985\n",
      "Epoch [9/20], Step [7/7], Loss: 0.5999\n",
      "Epoch [10/20], Step [1/7], Loss: 0.1191\n",
      "Epoch [10/20], Step [2/7], Loss: 0.0995\n",
      "Epoch [10/20], Step [3/7], Loss: 0.0741\n",
      "Epoch [10/20], Step [4/7], Loss: 0.1306\n",
      "Epoch [10/20], Step [5/7], Loss: 0.1059\n",
      "Epoch [10/20], Step [6/7], Loss: 0.1672\n",
      "Epoch [10/20], Step [7/7], Loss: 0.1441\n",
      "Epoch [11/20], Step [1/7], Loss: 0.0057\n",
      "Epoch [11/20], Step [2/7], Loss: 0.1181\n",
      "Epoch [11/20], Step [3/7], Loss: 0.1183\n",
      "Epoch [11/20], Step [4/7], Loss: 0.1216\n",
      "Epoch [11/20], Step [5/7], Loss: 0.2888\n",
      "Epoch [11/20], Step [6/7], Loss: 0.2531\n",
      "Epoch [11/20], Step [7/7], Loss: 0.2287\n",
      "Epoch [12/20], Step [1/7], Loss: 0.0251\n",
      "Epoch [12/20], Step [2/7], Loss: 0.0478\n",
      "Epoch [12/20], Step [3/7], Loss: 0.0698\n",
      "Epoch [12/20], Step [4/7], Loss: 0.0747\n",
      "Epoch [12/20], Step [5/7], Loss: 0.0603\n",
      "Epoch [12/20], Step [6/7], Loss: 0.0702\n",
      "Epoch [12/20], Step [7/7], Loss: 0.0894\n",
      "Epoch [13/20], Step [1/7], Loss: 0.0180\n",
      "Epoch [13/20], Step [2/7], Loss: 0.0949\n",
      "Epoch [13/20], Step [3/7], Loss: 0.1285\n",
      "Epoch [13/20], Step [4/7], Loss: 0.1055\n",
      "Epoch [13/20], Step [5/7], Loss: 0.1251\n",
      "Epoch [13/20], Step [6/7], Loss: 0.1476\n",
      "Epoch [13/20], Step [7/7], Loss: 0.1274\n",
      "Epoch [14/20], Step [1/7], Loss: 0.0191\n",
      "Epoch [14/20], Step [2/7], Loss: 0.0109\n",
      "Epoch [14/20], Step [3/7], Loss: 0.0179\n",
      "Epoch [14/20], Step [4/7], Loss: 0.2913\n",
      "Epoch [14/20], Step [5/7], Loss: 0.4005\n",
      "Epoch [14/20], Step [6/7], Loss: 0.3373\n",
      "Epoch [14/20], Step [7/7], Loss: 0.4240\n",
      "Epoch [15/20], Step [1/7], Loss: 0.0543\n",
      "Epoch [15/20], Step [2/7], Loss: 0.0400\n",
      "Epoch [15/20], Step [3/7], Loss: 0.0388\n",
      "Epoch [15/20], Step [4/7], Loss: 0.0313\n",
      "Epoch [15/20], Step [5/7], Loss: 0.1307\n",
      "Epoch [15/20], Step [6/7], Loss: 0.1166\n",
      "Epoch [15/20], Step [7/7], Loss: 0.1000\n",
      "Epoch [16/20], Step [1/7], Loss: 0.0132\n",
      "Epoch [16/20], Step [2/7], Loss: 0.0068\n",
      "Epoch [16/20], Step [3/7], Loss: 0.0602\n",
      "Epoch [16/20], Step [4/7], Loss: 0.0758\n",
      "Epoch [16/20], Step [5/7], Loss: 0.0607\n",
      "Epoch [16/20], Step [6/7], Loss: 0.0603\n",
      "Epoch [16/20], Step [7/7], Loss: 0.0532\n",
      "Epoch [17/20], Step [1/7], Loss: 0.9317\n",
      "Epoch [17/20], Step [2/7], Loss: 0.4883\n",
      "Epoch [17/20], Step [3/7], Loss: 0.3262\n",
      "Epoch [17/20], Step [4/7], Loss: 0.3658\n",
      "Epoch [17/20], Step [5/7], Loss: 0.2946\n",
      "Epoch [17/20], Step [6/7], Loss: 0.2531\n",
      "Epoch [17/20], Step [7/7], Loss: 0.2689\n",
      "Epoch [18/20], Step [1/7], Loss: 0.0638\n",
      "Epoch [18/20], Step [2/7], Loss: 0.0336\n",
      "Epoch [18/20], Step [3/7], Loss: 0.0261\n",
      "Epoch [18/20], Step [4/7], Loss: 0.0230\n",
      "Epoch [18/20], Step [5/7], Loss: 0.0196\n",
      "Epoch [18/20], Step [6/7], Loss: 0.0419\n",
      "Epoch [18/20], Step [7/7], Loss: 0.0382\n",
      "Epoch [19/20], Step [1/7], Loss: 0.0008\n",
      "Epoch [19/20], Step [2/7], Loss: 0.0574\n",
      "Epoch [19/20], Step [3/7], Loss: 0.0409\n",
      "Epoch [19/20], Step [4/7], Loss: 0.0644\n",
      "Epoch [19/20], Step [5/7], Loss: 0.1218\n",
      "Epoch [19/20], Step [6/7], Loss: 0.1202\n",
      "Epoch [19/20], Step [7/7], Loss: 0.1030\n",
      "Epoch [20/20], Step [1/7], Loss: 0.0025\n",
      "Epoch [20/20], Step [2/7], Loss: 0.0027\n",
      "Epoch [20/20], Step [3/7], Loss: 0.0202\n",
      "Epoch [20/20], Step [4/7], Loss: 0.0152\n",
      "Epoch [20/20], Step [5/7], Loss: 0.0150\n",
      "Epoch [20/20], Step [6/7], Loss: 0.1024\n",
      "Epoch [20/20], Step [7/7], Loss: 0.0878\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 1. Define a simple text dataset and vocabulary ---\n",
    "# FIX: Added much longer sentences to the training data.\n",
    "TEXT_DATA = [\n",
    "    \"hello world and this is a much longer sentence than before\",\n",
    "    \"python programming is fun and easy to learn especially for beginners\",\n",
    "    \"i love deep learning with convolutional neural networks and attention\",\n",
    "    \"deep learning is a powerful tool in artificial intelligence for language modeling tasks\"\n",
    "]\n",
    "\n",
    "# Create vocabulary\n",
    "vocab = sorted(list(set(\" \".join(TEXT_DATA).split())))\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_data, word_to_idx, sequence_length):\n",
    "        self.sequences = []\n",
    "        for sentence in text_data:\n",
    "            words = sentence.split()\n",
    "            # This condition will now be met for the longer sentences\n",
    "            if len(words) > sequence_length:\n",
    "                for i in range(len(words) - sequence_length):\n",
    "                    input_seq = [word_to_idx[word] for word in words[i:i+sequence_length]]\n",
    "                    target_word = word_to_idx[words[i+sequence_length]]\n",
    "                    self.sequences.append((torch.tensor(input_seq), torch.tensor(target_word)))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx]\n",
    "\n",
    "# --- 2. Attention Mechanism for 1D sequences ---\n",
    "class AttentionMessagePassing(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(AttentionMessagePassing, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.query_proj = nn.Linear(in_features, in_features // 2)\n",
    "        self.key_proj = nn.Linear(in_features, in_features // 2)\n",
    "        self.value_proj = nn.Linear(in_features, in_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, in_features = x.shape\n",
    "        query = self.query_proj(x)\n",
    "        key = self.key_proj(x)\n",
    "        value = self.value_proj(x)\n",
    "        key_t = key.permute(0, 2, 1)\n",
    "        \n",
    "        attention_scores = torch.bmm(query, key_t)\n",
    "        attention_scores = attention_scores / np.sqrt(query.size(-1))\n",
    "        \n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(device)\n",
    "        attention_scores.masked_fill_(mask, -1e9)\n",
    "        \n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "        message_passed_features = torch.bmm(attention_weights, value)\n",
    "        \n",
    "        output = message_passed_features + x\n",
    "        return output\n",
    "\n",
    "# --- 3. The new TextCNN Architecture with Attention ---\n",
    "class AttentionTextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, sequence_length):\n",
    "        super(AttentionTextCNN, self).__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=embedding_dim, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.final_seq_len = self._compute_final_seq_len()\n",
    "        \n",
    "        self.attention_block = AttentionMessagePassing(in_features=256)\n",
    "        \n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * self.final_seq_len, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, vocab_size)\n",
    "        )\n",
    "\n",
    "    def _compute_final_seq_len(self):\n",
    "        l_in = self.sequence_length\n",
    "        l_out_conv1 = (l_in + 2*1 - 3) + 1\n",
    "        l_out_pool1 = torch.floor(torch.tensor((l_out_conv1 - 2) / 2)) + 1\n",
    "        l_out_conv2 = (l_out_pool1 + 2*1 - 3) + 1\n",
    "        l_out_pool2 = torch.floor(torch.tensor((l_out_conv2 - 2) / 2)) + 1\n",
    "        \n",
    "        return int(l_out_pool2.item())\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.embedding(x).permute(0, 2, 1)\n",
    "        conv_features = self.conv_block(embeddings)\n",
    "        conv_features_t = conv_features.permute(0, 2, 1)\n",
    "        attended_features = self.attention_block(conv_features_t)\n",
    "        logits = self.fc_block(attended_features)\n",
    "        return logits\n",
    "\n",
    "def train_model():\n",
    "    # Hyperparameters\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 2\n",
    "    num_epochs = 20\n",
    "    # FIX: Increased sequence length to a value that won't result in an empty tensor.\n",
    "    sequence_length = 8\n",
    "    embedding_dim = 128\n",
    "    \n",
    "    # Data loading\n",
    "    train_dataset = TextDataset(TEXT_DATA, word_to_idx, sequence_length)\n",
    "    \n",
    "    # FIX: Added a check to prevent the error\n",
    "    if len(train_dataset) == 0:\n",
    "        print(\"Error: Dataset is empty.\")\n",
    "        print(f\"Please increase the length of sentences in TEXT_DATA or decrease the `sequence_length` (currently {sequence_length}).\")\n",
    "        return\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = AttentionTextCNN(vocab_size, embedding_dim, sequence_length).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if (i+1) % 1 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/(i+1):.4f}')\n",
    "    \n",
    "    print(\"Training finished.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e318639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading a small streaming portion of the C4 dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4158/3481312030.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  l_out_pool2 = torch.floor(torch.tensor((l_out_conv2 - 2) / 2)) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch [1/25], Step [50], Loss: 7.6677\n",
      "Epoch [1/25], Step [100], Loss: 7.5824\n",
      "Epoch [1/25], Step [150], Loss: 7.4749\n",
      "Epoch [1/25], Step [200], Loss: 7.4262\n",
      "Epoch [1/25], Step [250], Loss: 7.3438\n",
      "Epoch [1/25], Step [300], Loss: 7.2747\n",
      "Epoch [1/25], Step [350], Loss: 7.2948\n",
      "Epoch [1/25], Step [400], Loss: 7.2955\n",
      "Epoch [1/25], Step [450], Loss: 7.1711\n",
      "Epoch [1/25], Step [500], Loss: 7.1431\n",
      "Epoch [1/25], Step [550], Loss: 7.0906\n",
      "Epoch [1/25], Step [600], Loss: 7.1088\n",
      "Epoch [1/25], Step [650], Loss: 7.1156\n",
      "Epoch [1/25], Step [700], Loss: 7.0343\n",
      "Epoch [1/25], Step [750], Loss: 7.1469\n",
      "Epoch [1/25], Step [800], Loss: 7.0802\n",
      "Epoch [1/25], Step [850], Loss: 6.9791\n",
      "Epoch [1/25], Step [900], Loss: 6.9719\n",
      "Epoch [1/25], Step [950], Loss: 6.9507\n",
      "Epoch [1/25], Step [1000], Loss: 6.9272\n",
      "Epoch [1/25], Step [1050], Loss: 6.9384\n",
      "Epoch [1/25], Step [1100], Loss: 6.9215\n",
      "Epoch [1/25], Step [1150], Loss: 6.8901\n",
      "Epoch [1/25], Step [1200], Loss: 6.9296\n",
      "Epoch [1/25], Step [1250], Loss: 6.8588\n",
      "Epoch [1/25], Step [1300], Loss: 6.8576\n",
      "Epoch [1/25], Step [1350], Loss: 6.8470\n",
      "Epoch [1/25], Step [1400], Loss: 6.8711\n",
      "Epoch [1/25], Step [1450], Loss: 6.9601\n",
      "Epoch [1/25], Step [1500], Loss: 6.8655\n",
      "Epoch [1/25], Step [1550], Loss: 6.8582\n",
      "Epoch [1/25], Step [1600], Loss: 6.8529\n",
      "Epoch [1/25], Step [1650], Loss: 6.7266\n",
      "Epoch [1/25], Step [1700], Loss: 6.7789\n",
      "Epoch [1/25], Step [1750], Loss: 6.7547\n",
      "Epoch [1/25], Step [1800], Loss: 6.7761\n",
      "Epoch [1/25], Step [1850], Loss: 6.7899\n",
      "Epoch [1/25], Step [1900], Loss: 6.6969\n",
      "Epoch [1/25], Step [1950], Loss: 6.7525\n",
      "Epoch [1/25], Step [2000], Loss: 6.6958\n",
      "Epoch [1/25], Step [2050], Loss: 6.7772\n",
      "Epoch [1/25], Step [2100], Loss: 6.7736\n",
      "Epoch [1/25], Step [2150], Loss: 6.7318\n",
      "Epoch [1/25], Step [2200], Loss: 6.7378\n",
      "Epoch [1/25], Step [2250], Loss: 6.6858\n",
      "Epoch [1/25], Step [2300], Loss: 6.5974\n",
      "Epoch [1/25], Step [2350], Loss: 6.7515\n",
      "Epoch [1/25], Step [2400], Loss: 6.7119\n",
      "Epoch [1/25], Step [2450], Loss: 6.6763\n",
      "Epoch [1/25], Step [2500], Loss: 6.6932\n",
      "Epoch [1/25], Step [2550], Loss: 6.7406\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 196\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining finished.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    195\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 196\u001b[0m     train_model()\n",
      "Cell \u001b[0;32mIn[17], line 158\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    155\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    156\u001b[0m \u001b[39m# FIX: The total number of batches is unknown, so we can't use len(train_loader).\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39m# We will track the step count manually.\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m    159\u001b[0m     \u001b[39m# Batches from DataLoader are already tensors\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     inputs \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    161\u001b[0m     labels \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:32\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m possibly_batched_index:\n\u001b[1;32m     31\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m         data\u001b[39m.\u001b[39mappend(\u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_iter))\n\u001b[1;32m     33\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mended \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/iterable_dataset.py:2361\u001b[0m, in \u001b[0;36mIterableDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2358\u001b[0m         \u001b[39myield\u001b[39;00m formatter\u001b[39m.\u001b[39mformat_row(pa_table)\n\u001b[1;32m   2359\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m-> 2361\u001b[0m \u001b[39mfor\u001b[39;00m key, example \u001b[39min\u001b[39;00m ex_iterable:\n\u001b[1;32m   2362\u001b[0m     \u001b[39m# no need to format thanks to FormattedExamplesIterable\u001b[39;00m\n\u001b[1;32m   2363\u001b[0m     \u001b[39myield\u001b[39;00m example\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/iterable_dataset.py:1107\u001b[0m, in \u001b[0;36mMappedExamplesIterable.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[39myield\u001b[39;00m key, formatter\u001b[39m.\u001b[39mformat_row(pa_table)\n\u001b[1;32m   1106\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/iterable_dataset.py:1286\u001b[0m, in \u001b[0;36mMappedExamplesIterable._iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatched:\n\u001b[1;32m   1281\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m   1282\u001b[0m         (key, transformed_example)\n\u001b[1;32m   1283\u001b[0m         \u001b[39mfor\u001b[39;00m key, transformed_batch \u001b[39min\u001b[39;00m outputs\n\u001b[1;32m   1284\u001b[0m         \u001b[39mfor\u001b[39;00m transformed_example \u001b[39min\u001b[39;00m _batch_to_examples(transformed_batch)\n\u001b[1;32m   1285\u001b[0m     )\n\u001b[0;32m-> 1286\u001b[0m \u001b[39mfor\u001b[39;00m key, transformed_example \u001b[39min\u001b[39;00m outputs:\n\u001b[1;32m   1287\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state_dict \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state_dict[\u001b[39m\"\u001b[39m\u001b[39mprevious_state\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1288\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state_dict[\u001b[39m\"\u001b[39m\u001b[39mnum_examples_since_previous_state\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/iterable_dataset.py:1271\u001b[0m, in \u001b[0;36mMappedExamplesIterable._iter.<locals>.iter_outputs\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1269\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatched:\n\u001b[1;32m   1270\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state_dict[\u001b[39m\"\u001b[39m\u001b[39mprevious_state_example_idx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m current_idx\n\u001b[0;32m-> 1271\u001b[0m \u001b[39myield\u001b[39;00m i, apply_function(key_example, i)\n\u001b[1;32m   1272\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state_dict:\n\u001b[1;32m   1273\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatched:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/iterable_dataset.py:1201\u001b[0m, in \u001b[0;36mMappedExamplesIterable._iter.<locals>.apply_function\u001b[0;34m(key_example, indices)\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[1;32m   1200\u001b[0m inputs, fn_args, additional_args, fn_kwargs \u001b[39m=\u001b[39m prepare_inputs(key_example, indices)\n\u001b[0;32m-> 1201\u001b[0m processed_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   1202\u001b[0m \u001b[39mreturn\u001b[39;00m prepare_outputs(key_example, inputs, processed_inputs)\n",
      "Cell \u001b[0;32mIn[17], line 120\u001b[0m, in \u001b[0;36mtrain_model.<locals>.preprocess_function\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_function\u001b[39m(examples):\n\u001b[1;32m    119\u001b[0m     inputs \u001b[39m=\u001b[39m examples[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 120\u001b[0m     tokenized_input \u001b[39m=\u001b[39m tokenizer(\n\u001b[1;32m    121\u001b[0m         inputs,\n\u001b[1;32m    122\u001b[0m         max_length\u001b[39m=\u001b[39;49msequence_length,\n\u001b[1;32m    123\u001b[0m         padding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmax_length\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    124\u001b[0m         truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    125\u001b[0m         return_tensors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    126\u001b[0m     )\n\u001b[1;32m    128\u001b[0m     \u001b[39m# Shift the labels for next-token prediction\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     input_ids \u001b[39m=\u001b[39m tokenized_input[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2520\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2518\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2519\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2520\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_one(text\u001b[39m=\u001b[39;49mtext, text_pair\u001b[39m=\u001b[39;49mtext_pair, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mall_kwargs)\n\u001b[1;32m   2521\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2522\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2626\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2606\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m   2607\u001b[0m         batch_text_or_text_pairs\u001b[39m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   2608\u001b[0m         add_special_tokens\u001b[39m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2623\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2624\u001b[0m     )\n\u001b[1;32m   2625\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2626\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode_plus(\n\u001b[1;32m   2627\u001b[0m         text\u001b[39m=\u001b[39;49mtext,\n\u001b[1;32m   2628\u001b[0m         text_pair\u001b[39m=\u001b[39;49mtext_pair,\n\u001b[1;32m   2629\u001b[0m         add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2630\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m   2631\u001b[0m         truncation\u001b[39m=\u001b[39;49mtruncation,\n\u001b[1;32m   2632\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2633\u001b[0m         stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2634\u001b[0m         is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2635\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2636\u001b[0m         return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2637\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2638\u001b[0m         return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2639\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2640\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2641\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2642\u001b[0m         return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2643\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2644\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2645\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2699\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2689\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2690\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2691\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m   2692\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2697\u001b[0m )\n\u001b[0;32m-> 2699\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_encode_plus(\n\u001b[1;32m   2700\u001b[0m     text\u001b[39m=\u001b[39;49mtext,\n\u001b[1;32m   2701\u001b[0m     text_pair\u001b[39m=\u001b[39;49mtext_pair,\n\u001b[1;32m   2702\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2703\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[1;32m   2704\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[1;32m   2705\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2706\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2707\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2708\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2709\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2710\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2711\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2712\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2713\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2714\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2715\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2716\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2717\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2718\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/tokenization_utils.py:649\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mif\u001b[39;00m return_offsets_mapping:\n\u001b[1;32m    641\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    642\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    643\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhttps://github.com/huggingface/transformers/pull/2674\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 649\u001b[0m first_ids \u001b[39m=\u001b[39m get_input_ids(text)\n\u001b[1;32m    650\u001b[0m second_ids \u001b[39m=\u001b[39m get_input_ids(text_pair) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_for_model(\n\u001b[1;32m    653\u001b[0m     first_ids,\n\u001b[1;32m    654\u001b[0m     pair_ids\u001b[39m=\u001b[39msecond_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    668\u001b[0m     verbose\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m    669\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/tokenization_utils.py:616\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus.<locals>.get_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_input_ids\u001b[39m(text):\n\u001b[1;32m    615\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 616\u001b[0m         tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenize(text, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    617\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_tokens_to_ids(tokens)\n\u001b[1;32m    618\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(text) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(text[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/tokenization_utils.py:547\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m         tokenized_text\u001b[39m.\u001b[39mappend(token)\n\u001b[1;32m    546\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 547\u001b[0m         tokenized_text\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokenize(token))\n\u001b[1;32m    548\u001b[0m \u001b[39m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[39mreturn\u001b[39;00m tokenized_text\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/bert/tokenization_bert.py:244\u001b[0m, in \u001b[0;36mBertTokenizer._tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    242\u001b[0m split_tokens \u001b[39m=\u001b[39m []\n\u001b[1;32m    243\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_basic_tokenize:\n\u001b[0;32m--> 244\u001b[0m     \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbasic_tokenizer\u001b[39m.\u001b[39;49mtokenize(text, never_split\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mall_special_tokens):\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m         \u001b[39m# If the token is part of the never_split set\u001b[39;00m\n\u001b[1;32m    247\u001b[0m         \u001b[39mif\u001b[39;00m token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbasic_tokenizer\u001b[39m.\u001b[39mnever_split:\n\u001b[1;32m    248\u001b[0m             split_tokens\u001b[39m.\u001b[39mappend(token)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/bert/tokenization_bert.py:411\u001b[0m, in \u001b[0;36mBasicTokenizer.tokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39m# union() returns a new set by concatenating the two sets.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m never_split \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnever_split\u001b[39m.\u001b[39munion(\u001b[39mset\u001b[39m(never_split)) \u001b[39mif\u001b[39;00m never_split \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnever_split\n\u001b[0;32m--> 411\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_clean_text(text)\n\u001b[1;32m    413\u001b[0m \u001b[39m# This was added on November 1st, 2018 for the multilingual and Chinese\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[39m# models. This is also applied to the English models now, but it doesn't\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[39m# matter since the English models were not trained on any Chinese data\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[39m# and generally don't have any Chinese data in them (there are Chinese\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m# characters in the vocabulary because Wikipedia does have some Chinese\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[39m# words in the English Wikipedia.).\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenize_chinese_chars:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/bert/tokenization_bert.py:516\u001b[0m, in \u001b[0;36mBasicTokenizer._clean_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    514\u001b[0m         output\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    515\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 516\u001b[0m         output\u001b[39m.\u001b[39mappend(char)\n\u001b[1;32m    517\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(output)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "# Set the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 1. Attention Mechanism for 1D sequences ---\n",
    "class AttentionMessagePassing(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(AttentionMessagePassing, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.query_proj = nn.Linear(in_features, in_features // 2)\n",
    "        self.key_proj = nn.Linear(in_features, in_features // 2)\n",
    "        self.value_proj = nn.Linear(in_features, in_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, in_features = x.shape\n",
    "        query = self.query_proj(x)\n",
    "        key = self.key_proj(x)\n",
    "        value = self.value_proj(x)\n",
    "        key_t = key.permute(0, 2, 1)\n",
    "        \n",
    "        attention_scores = torch.bmm(query, key_t)\n",
    "        attention_scores = attention_scores / np.sqrt(query.size(-1))\n",
    "        \n",
    "        # We need a causality mask for language modeling\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(device)\n",
    "        attention_scores.masked_fill_(mask, -1e9)\n",
    "        \n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "        message_passed_features = torch.bmm(attention_weights, value)\n",
    "        \n",
    "        output = message_passed_features + x\n",
    "        return output\n",
    "\n",
    "# --- 2. The new TextCNN Architecture with Attention ---\n",
    "class AttentionTextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, sequence_length):\n",
    "        super(AttentionTextCNN, self).__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            # Conv1d expects input shape (batch, channels, sequence_length)\n",
    "            nn.Conv1d(in_channels=embedding_dim, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.final_seq_len = self._compute_final_seq_len()\n",
    "        \n",
    "        self.attention_block = AttentionMessagePassing(in_features=256)\n",
    "        \n",
    "        # FIX: Removed nn.Flatten() and adjusted Linear layer to work on a per-token basis.\n",
    "        # This is the correct way to build a sequence-to-sequence model for language modeling.\n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, vocab_size)\n",
    "        )\n",
    "\n",
    "    def _compute_final_seq_len(self):\n",
    "        l_in = self.sequence_length\n",
    "        l_out_conv1 = (l_in + 2*1 - 3) + 1\n",
    "        l_out_pool1 = torch.floor(torch.tensor((l_out_conv1 - 2) / 2)) + 1\n",
    "        l_out_conv2 = (l_out_pool1 + 2*1 - 3) + 1\n",
    "        l_out_pool2 = torch.floor(torch.tensor((l_out_conv2 - 2) / 2)) + 1\n",
    "        \n",
    "        return int(l_out_pool2.item())\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.embedding(x).permute(0, 2, 1)\n",
    "        conv_features = self.conv_block(embeddings)\n",
    "        conv_features_t = conv_features.permute(0, 2, 1)\n",
    "        attended_features = self.attention_block(conv_features_t)\n",
    "        # FIX: The fc_block now processes the attended features without flattening.\n",
    "        logits = self.fc_block(attended_features)\n",
    "        return logits\n",
    "\n",
    "# --- 3. Main training function updated for C4 dataset ---\n",
    "def train_model():\n",
    "    # Hyperparameters\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 256\n",
    "    num_epochs = 25\n",
    "    sequence_length = 128\n",
    "    embedding_dim = 128\n",
    "    \n",
    "    # ----------------------------------------\n",
    "    # 1. Load C4 dataset (streaming) and Bert tokenizer\n",
    "    # ----------------------------------------\n",
    "    print(\"Loading a small streaming portion of the C4 dataset...\")\n",
    "    dataset = load_dataset(\"allenai/c4\", \"en\", split=\"train\", streaming=True)\n",
    "    \n",
    "    # Use a simpler, pre-trained tokenizer: BertTokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    vocab_size = len(tokenizer)\n",
    "    \n",
    "    # We will use a smaller sample for a quicker demonstration.\n",
    "    dataset_sample = dataset\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 2. Pre-process the dataset with the tokenizer\n",
    "    # ----------------------------------------\n",
    "    def preprocess_function(examples):\n",
    "        inputs = examples[\"text\"]\n",
    "        tokenized_input = tokenizer(\n",
    "            inputs,\n",
    "            max_length=sequence_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Shift the labels for next-token prediction\n",
    "        input_ids = tokenized_input['input_ids'].squeeze(0)\n",
    "        labels = torch.cat((input_ids[1:], torch.tensor([tokenizer.pad_token_id])))\n",
    "        \n",
    "        return {\"input_ids\": input_ids, \"labels\": labels}\n",
    "    \n",
    "    # Apply the preprocessing to the streaming dataset\n",
    "    processed_dataset = dataset_sample.map(preprocess_function, batched=False)\n",
    "    \n",
    "    # We use the processed streaming dataset directly with the DataLoader\n",
    "    train_loader = DataLoader(processed_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # ----------------------------------------\n",
    "    # 3. Model, Loss, and Optimizer\n",
    "    # ----------------------------------------\n",
    "    model = AttentionTextCNN(vocab_size, embedding_dim, sequence_length).to(device)\n",
    "    # Ignore the pad token in the loss\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    # ----------------------------------------\n",
    "    # 4. Training Loop\n",
    "    # ----------------------------------------\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        # FIX: The total number of batches is unknown, so we can't use len(train_loader).\n",
    "        # We will track the step count manually.\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            # Batches from DataLoader are already tensors\n",
    "            inputs = batch[\"input_ids\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # The model's output sequence length might be different from the input\n",
    "            # due to pooling. We need to truncate the labels to match.\n",
    "            outputs_seq_len = outputs.size(1)\n",
    "            labels = labels[:, :outputs_seq_len]\n",
    "\n",
    "            # Reshape for loss calculation: (B*L, V) vs (B*L)\n",
    "            outputs_flat = outputs.view(-1, outputs.size(-1))\n",
    "            # FIX: Use .reshape() instead of .view() to handle non-contiguous tensors\n",
    "            labels_flat = labels.reshape(-1)\n",
    "            \n",
    "            loss = criterion(outputs_flat, labels_flat)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}], Loss: {loss.item():.4f}')\n",
    "\n",
    "            torch.save(model.state_dict(), 'language-model')\n",
    "        \n",
    "        # FIX: The total number of batches is unknown, so average loss is not meaningful.\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Total Loss: {total_loss:.4f}')\n",
    "    \n",
    "    print(\"Training finished.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e77b4c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Bert tokenizer...\n",
      "Initializing the model for demonstration purposes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4158/3481312030.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  l_out_pool2 = torch.floor(torch.tensor((l_out_conv2 - 2) / 2)) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text...\n",
      "\n",
      "--- Generated Text ---\n",
      "hello world hello hello hello hello are there are are there the there are are are are are are are are are, are are are are are are are are are are are are are are are are are are are, are are is are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are are? are are are are are are are are are are are are\n",
      "----------------------\n",
      "\n",
      "Script execution finished.\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, tokenizer, prompt, max_length=50, sequence_length=0):\n",
    "    \"\"\"\n",
    "    Generates text from the model given a starting prompt.\n",
    "    \"\"\"\n",
    "    print(\"Generating text...\")\n",
    "    \n",
    "    try:\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "        # Loop to generate new tokens\n",
    "        for _ in range(max_length):\n",
    "            # Pad the input_ids to the model's fixed sequence length\n",
    "            # This is necessary because the CNN architecture is not\n",
    "            # designed for variable-length inputs.\n",
    "            current_len = input_ids.size(1)\n",
    "            padding_needed = sequence_length - current_len\n",
    "            if padding_needed > 0:\n",
    "                padded_input_ids = F.pad(input_ids, (0, padding_needed), 'constant', tokenizer.pad_token_id)\n",
    "            else:\n",
    "                padded_input_ids = input_ids[:, -sequence_length:]\n",
    "\n",
    "            # Get the model's output on the padded sequence\n",
    "            outputs = model(padded_input_ids)\n",
    "\n",
    "            # Get the predictions for the last non-padded token\n",
    "            predictions = outputs[:, -1, :]\n",
    "            predicted_id = torch.argmax(predictions, dim=-1)\n",
    "            \n",
    "            # Add the new token to the original sequence\n",
    "            input_ids = torch.cat([input_ids, predicted_id.unsqueeze(1)], dim=-1)\n",
    "\n",
    "        # Decode the token IDs back to text.\n",
    "        generated_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "        return generated_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during text generation: {e}\")\n",
    "        return \"Text generation failed.\"\n",
    "\n",
    "sequence_length = 128\n",
    "embedding_dim = 128\n",
    "\n",
    "# 1. Load Bert tokenizer\n",
    "print(\"Loading Bert tokenizer...\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "vocab_size = len(tokenizer)\n",
    "\n",
    "# 2. Initialize the model (without training)\n",
    "print(\"Initializing the model for demonstration purposes...\")\n",
    "model = AttentionTextCNN(vocab_size, embedding_dim, sequence_length).to(device)\n",
    "\n",
    "model_state_dict = torch.load('language-model', map_location=device)\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "# 3. Define the starting prompt\n",
    "start_prompt = \"hello world\"\n",
    "\n",
    "# 4. Generate text with the (simulated) trained model\n",
    "generated_text = generate_text(model, tokenizer, start_prompt, sequence_length)\n",
    "\n",
    "print(\"\\n--- Generated Text ---\")\n",
    "print(generated_text)\n",
    "print(\"----------------------\")\n",
    "\n",
    "print(\"\\nScript execution finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
